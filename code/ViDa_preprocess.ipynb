{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import pandas as pd \n",
    "\n",
    "from vida.data_processing.load_data import *\n",
    "from vida.data_processing.convertor import *\n",
    "from vida.data_processing.misc import *\n",
    "from vida.data_processing.split_data import *\n",
    "\n",
    "from vida.model.scatter_transform import transform_dataset, get_normalized_moments"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import and Pre-processing Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Load multiple simulated trajectories from Mulistrand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# load dataset generated by Multistrand\n",
    "def read_1trj(f):\n",
    "    \"\"\"load text data and split it into individual trajectory \n",
    "    with seperated structure, time, and energy\n",
    "\n",
    "    Args:\n",
    "        f: text file with trajectory dp notation, time, energy, and if paired (1) or not (0)\n",
    "            eg. '..((((....)))).', 't=0.000000103', 'seconds, dG=  0.26 kcal/mol\\n', \"0\"\n",
    "        FINAL_STRUCTURE: final state structure, eg. \"..((((....)))).\"\n",
    "        type: 'Single' or 'Multiple' mode\n",
    "    Returns:\n",
    "        [list]: dot-parenthesis notation, time floats, energy floats, paired or not\n",
    "            eg. ['...............', 0.0, -12.0, 1]\n",
    "    \"\"\"\n",
    "    S_dp = []; S_time = []; S_energy = []; S_pair = []\n",
    "    \n",
    "    for s in f:\n",
    "        ss = s.split(\" \")\n",
    "        s_dp=ss[0] # dp notation\n",
    "        s_time = float(ss[1].split(\"=\",1)[1]) # simulation time\n",
    "        s_energy = float(ss[3].split(\"=\")[1].split(\"kcal\")[0]) # energy\n",
    "        s_pair = int(ss[-1]) # paired or not\n",
    "        \n",
    "        S_dp.append(s_dp)\n",
    "        S_time.append(s_time)\n",
    "        S_energy.append(s_energy)\n",
    "        S_pair.append(s_pair)\n",
    "        \n",
    "    return [S_dp,S_time,S_energy,S_pair]\n",
    "\n",
    "\n",
    "# load multiple trajectories from multiple files\n",
    "def read_Gao(fpath,rxn,num_files=100):\n",
    "    trajs_states, trajs_times, trajs_energies, trajs_pairs = [],[],[],[]\n",
    "    \n",
    "    for i in range(num_files):\n",
    "        STR_name = f\"{fpath}/{rxn}/{rxn}-{i}.txt\"\n",
    "        f = open(STR_name, 'r') \n",
    "        TRJ = read_1trj(f)\n",
    "        trajs_states.append(TRJ[0])\n",
    "        trajs_times.append(TRJ[1])\n",
    "        trajs_energies.append(TRJ[2])\n",
    "        trajs_pairs.append(TRJ[3])\n",
    "    \n",
    "    trajs_states = np.array(trajs_states, dtype=object)\n",
    "    trajs_times = np.array(trajs_times, dtype=object)\n",
    "    trajs_energies = np.array(trajs_energies, dtype=object)\n",
    "    trajs_pairs = np.array(trajs_pairs, dtype=object)\n",
    "        \n",
    "    return trajs_states, trajs_times, trajs_energies, trajs_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rxn = \"Gao-P4T4\"\n",
    "fpath= f\"../raw_data/Gao-data\"\n",
    "\n",
    "trajs_states, trajs_times, trajs_energies, trajs_pairs = read_Gao(fpath,rxn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load multiple trajectories from multiple files\n",
    "\n",
    "# # rxn = \"PT4_hairpin\"\n",
    "# rxn = \"Gao-P4T4\"\n",
    "# folder_name = f\"../raw_data/Gao-data/{rxn}/{rxn}\"\n",
    "\n",
    "# # define absorbing (final) state structure\n",
    "# FINAL_STRUCTURE = \"(((((((((((((((((((((((((+)))))))))))))))))))))))))\"\n",
    "# num_files = 100\n",
    "\n",
    "# SIMS,SIMS_retrieve,SIMS_concat = load_multitrj(folder_name,FINAL_STRUCTURE,num_files)\n",
    "\n",
    "# print(\"SIMS: \", len(SIMS))\n",
    "# print(\"SIMS_retrieve: \", SIMS_retrieve.shape)\n",
    "# print(\"SIMS_concat: \", len(SIMS_concat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert concantenate two individual structures to one structure \n",
    "def process_gao(dp_og):\n",
    "    dp = copy.deepcopy(dp_og)\n",
    "    for i in range(len(dp)):   \n",
    "        dp[i] = dp[i].replace(\"+\",\"\")\n",
    "    \n",
    "    return dp\n",
    "\n",
    "\n",
    "# convert concantenate two individual structures to one structure, and pair or not\n",
    "def process_hata(dp_og):\n",
    "    dp = copy.deepcopy(dp_og)\n",
    "    dp_pair = []\n",
    "    for i in range(len(dp)):\n",
    "        if \"&\" in dp[i]:\n",
    "            dp[i] = dp[i].replace(\"&\",\"\")\n",
    "            dp_pair.append(0)\n",
    "            \n",
    "        if \"+\" in dp[i]:\n",
    "            dp[i] = dp[i].replace(\"+\",\"\")\n",
    "            dp_pair.append(1)\n",
    "            \n",
    "    return np.array(dp), np.array(dp_pair)\n",
    "\n",
    "\n",
    "# cooncatanate all sturcutres for Gao dataset: \n",
    "def concat_gao(states, times, energies, pairs):\n",
    "    \n",
    "    SIMS_dp, SIMS_dp_og, SIMS_pair, SIMS_G, SIMS_T = [],[],[],[],[]\n",
    "    \n",
    "    for i in range(len(states)):\n",
    "        sims_dp = process_gao(states[i])\n",
    "        \n",
    "        SIMS_dp.append(sims_dp)\n",
    "        SIMS_dp_og.append(states[i])\n",
    "        SIMS_T.append(times[i])\n",
    "        SIMS_G.append(energies[i])\n",
    "        SIMS_pair.append(pairs[i])\n",
    "    \n",
    "    SIMS_dp = np.concatenate(SIMS_dp)\n",
    "    SIMS_dp_og = np.concatenate(SIMS_dp_og)\n",
    "    SIMS_pair = np.concatenate(SIMS_pair)\n",
    "    SIMS_G = np.concatenate(SIMS_G)\n",
    "    SIMS_T = np.concatenate(SIMS_T)\n",
    "        \n",
    "    return SIMS_dp, SIMS_dp_og, SIMS_pair, SIMS_G, SIMS_T\n",
    "\n",
    "\n",
    "# cooncatanate all sturcutres for Hata dataset:: \n",
    "def concat_hata(states, times, energies):\n",
    "    \n",
    "    SIMS_dp, SIMS_dp_og, SIMS_pair, SIMS_G, SIMS_T = [],[],[],[],[]\n",
    "    \n",
    "    for i in range(len(states)):\n",
    "        sims_dp, sims_pair = process_hata(states[i])\n",
    "\n",
    "        SIMS_dp.append(sims_dp)\n",
    "        SIMS_dp_og.append(states[i])\n",
    "        SIMS_pair.append(sims_pair)\n",
    "        SIMS_G.append(energies[i])\n",
    "        SIMS_T.append(times[i])\n",
    "    \n",
    "    SIMS_dp = np.concatenate(SIMS_dp)\n",
    "    SIMS_dp_og = np.concatenate(SIMS_dp_og)\n",
    "    SIMS_pair = np.concatenate(SIMS_pair)\n",
    "    SIMS_G = np.concatenate(SIMS_G)\n",
    "    SIMS_T = np.concatenate(SIMS_T)\n",
    "        \n",
    "    return SIMS_dp, SIMS_dp_og, SIMS_pair, SIMS_G, SIMS_T\n",
    "\n",
    "\n",
    "# get the unique structures and their corresponding indices\n",
    "def get_uniq(SIMS_dp, SIMS_dp_og, SIMS_pair, SIMS_G):\n",
    "    \n",
    "    indices_S = np.unique(SIMS_dp,return_index=True)[1]\n",
    "    \n",
    "    SIMS_dp_uniq = SIMS_dp[indices_S]\n",
    "    SIMS_dp_og_uniq = SIMS_dp_og[indices_S]\n",
    "    SIMS_pair_uniq = SIMS_pair[indices_S]\n",
    "    SIMS_G_uniq = SIMS_G[indices_S]\n",
    "        \n",
    "    # find index to recover to all data from unique data\n",
    "    coord_id_S = np.empty(len(SIMS_dp))\n",
    "    for i in range(len(SIMS_dp_uniq)):\n",
    "        temp = SIMS_dp == SIMS_dp_uniq[i]\n",
    "        indx = np.argwhere(temp==True)\n",
    "        coord_id_S[indx] = i\n",
    "    coord_id_S = coord_id_S.astype(int)\n",
    "\n",
    "    return SIMS_dp_uniq, SIMS_dp_og_uniq, SIMS_pair_uniq, SIMS_G_uniq, indices_S, coord_id_S\n",
    "\n",
    "\n",
    "# label the structural types\n",
    "def label_struc(trajs_types, SIMS_dp_og_uniq):\n",
    "    \n",
    "    SIMS_type_uniq = []\n",
    "    \n",
    "    for i in range(len(SIMS_dp_og_uniq)):\n",
    "        SIMS_type_uniq.append(trajs_types[SIMS_dp_og_uniq[i]])\n",
    "    SIMS_type_uniq = np.array(SIMS_type_uniq)\n",
    "    \n",
    "    return SIMS_type_uniq\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIMS_dp, SIMS_dp_og, SIMS_pair, SIMS_G, SIMS_T = concat_gao(trajs_states, trajs_times, trajs_energies, trajs_pairs)\n",
    "\n",
    "SIMS_dp_uniq, SIMS_dp_og_uniq, SIMS_pair_uniq, SIMS_G_uniq, indices_S, coord_id_S = get_uniq(SIMS_dp, SIMS_dp_og, SIMS_pair, SIMS_G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coord_id_S.shape, SIMS_dp_uniq.shape, SIMS_dp_og_uniq.shape, SIMS_pair_uniq.shape, SIMS_G_uniq.shape, indices_S.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "inpath = \"/Users/chenwei/Desktop/Github/ViDa/data/preprocess_data/preprocess_Gao-P4T4.pkl.gz\"\n",
    "file_name = os.path.basename(inpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Convert dot-paren to adjacency matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Dimenstions of SIM_adj list \n",
    "SIM_adj: N*m*m\n",
    "    N: number of states in the trajectory\n",
    "    m: number of nucleotides in the state (strand)\n",
    "\"\"\"\n",
    "# get multiple trajectories' data\n",
    "SIMS_adj, SIMS_G, SIMS_T, SIMS_HT, SIMS_pair, trj_id = sim_adj(SIMS_concat)\n",
    "print(SIMS_adj.shape,SIMS_G.shape,SIMS_T.shape,SIMS_HT.shape,SIMS_pair.shape,trj_id.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Get unique data except holding time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get unique states adjacency matrix with their occupancy density, get unique energy, time, if paired;\n",
    "# and their corresponding indices\n",
    "\n",
    "# multiple trajectories\n",
    "indices_S,occ_density_S,SIMS_adj_uniq,SIMS_G_uniq,SIMS_pair_uniq \\\n",
    "     = get_unique(SIMS_concat,SIMS_adj,SIMS_G,SIMS_pair) \n",
    "print(indices_S.shape, occ_density_S.shape, SIMS_adj_uniq.shape,SIMS_G_uniq.shape,SIMS_pair_uniq.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Get labeled trajectory data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # get trajectory data with its corresponding labels \n",
    "# # multiple trajectories\n",
    "SIMS_dict = label_structures(SIMS,indices_S)\n",
    "coord_id_S = SIMS_dict[:,-1].astype(int)\n",
    "SIMS_dict_uniq = np.array(SIMS)[indices_S]\n",
    "print(SIMS_dict.shape, coord_id_S.shape, SIMS_dict_uniq.shape)\n",
    "\n",
    "# find the structure having the largest occupancy density\n",
    "print(SIMS_retrieve[indices_S[occ_density_S.argmax()]])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Get unique holding time for each state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get unique holding time of unique states\n",
    "SIMS_HT_uniq = mean_holdingtime(SIMS_HT, indices_S, coord_id_S)\n",
    "print(SIMS_HT_uniq.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Convert adjacency matrix scattering coefficients"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SIMS_scar_uniq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Multiple trajectories\n",
    "scat_coeff_array_S = transform_dataset(SIMS_adj_uniq)\n",
    "SIMS_scar_uniq = get_normalized_moments(scat_coeff_array_S).squeeze()\n",
    "\n",
    "# get SIMS_scar based on SIMS_scar_uniq\n",
    "SIMS_scar = SIMS_scar_uniq[coord_id_S]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(SIMS_scar.shape, (np.unique(SIMS_scar,axis=0)).shape)\n",
    "print(SIMS_scar_uniq.shape, (np.unique(SIMS_scar_uniq,axis=0)).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # For large trajectories states\n",
    "# SIMS_scar_uniq1 = get_normalized_moments(transform_dataset(SIMS_adj_uniq[:60000])).squeeze()\n",
    "# SIMS_scar_uniq2 = get_normalized_moments(transform_dataset(SIMS_adj_uniq[60000:])).squeeze()\n",
    "# SIMS_scar_uniq = np.concatenate((SIMS_scar_uniq1,SIMS_scar_uniq2))\n",
    "\n",
    "# # get SIMS_scar based on SIMS_scar_uniq\n",
    "# SIMS_scar = SIMS_scar_uniq[coord_id_S]\n",
    "\n",
    "# print(SIMS_scar.shape, (np.unique(SIMS_scar,axis=0)).shape)\n",
    "# print(SIMS_scar_uniq.shape, (np.unique(SIMS_scar_uniq,axis=0)).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Save/load all obtained data to npz file for python,\n",
    "    Multiple trajectories\n",
    "\"\"\"\n",
    "# # save for python\n",
    "# fnpz_data = \"data/vida_data/helix_assoc/helix_assoc_{}_multrj_100epoch_py_temp.npz\".format(SEQ)\n",
    "# with open(fnpz_data, 'wb') as f:\n",
    "#     np.savez(f,\n",
    "#             # SIMS data\n",
    "#             SIMS_T=SIMS_T, SIMS_HT=SIMS_HT, SIMS_HT_uniq=SIMS_HT_uniq,\n",
    "#             SIMS_adj_uniq=SIMS_adj_uniq, SIMS_scar_uniq=SIMS_scar_uniq,\n",
    "#             SIMS_G_uniq=SIMS_G_uniq, SIMS_pair_uniq=SIMS_pair_uniq,\n",
    "#             SIMS_dict=SIMS_dict, SIMS_dict_uniq=SIMS_dict_uniq,\n",
    "#             # Indices\n",
    "#             coord_id_S=coord_id_S, indices_S=indices_S,trj_id=trj_id, occ_density_S=occ_density_S,\n",
    "#             # # embed data and occpancy density\n",
    "#             # data_embed=data_embed,\n",
    "#             # # plotting data\n",
    "#             # pca_coords=pca_coords, pca_all_coords=pca_all_coords,\n",
    "#             # phate_coords=phate_coords, phate_all_coords=phate_all_coords,\n",
    "#             # umap_coord_2d=umap_coord_2d, umap_all_coord_2d=umap_all_coord_2d,\n",
    "#             # umap_coord_3d=umap_coord_3d, umap_all_coord_3d=umap_all_coord_3d,\n",
    "#             # tsne_coord_2d=tsne_coord_2d, tsne_all_coord_2d=tsne_all_coord_2d,\n",
    "#             # tsne_coord_3d=tsne_coord_3d, tsne_all_coord_3d=tsne_all_coord_3d,\n",
    "#             )\n",
    "    \n",
    "# # multiple trajectories\n",
    "# fnpz_data = \"data/vida_data/helix_assoc/helix_assoc_PT4_multrj_100epoch_py_temp.npz\"\n",
    "# data_npz = np.load(fnpz_data)\n",
    "\n",
    "# # asssign data to variables\n",
    "# for var in data_npz.files:\n",
    "#      locals()[var] = data_npz[var]\n",
    "\n",
    "# # recover full data based on coord_id, indices, and unique data\n",
    "# SIMS_adj = SIMS_adj_uniq[coord_id_S]\n",
    "# SIMS_scar = SIMS_scar_uniq[coord_id_S]\n",
    "# SIMS_G = SIMS_G_uniq[coord_id_S]\n",
    "# SIMS_pair = SIMS_pair_uniq[coord_id_S]\n",
    "\n",
    "\n",
    "# print(SIMS_T.shape,SIMS_HT.shape,SIMS_HT_uniq.shape)\n",
    "# print(SIMS_adj.shape,SIMS_scar.shape,SIMS_G.shape,SIMS_HT.shape,SIMS_pair.shape)\n",
    "# print(SIMS_adj_uniq.shape,SIMS_scar_uniq.shape,SIMS_G_uniq.shape,SIMS_pair_uniq.shape) \n",
    "# print(SIMS_dict.shape,SIMS_dict_uniq.shape)\n",
    "# print(coord_id_S.shape,indices_S.shape,trj_id.shape,occ_density_S.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Shape of split data\n",
    "    train_data: [tr_adjs, tr_coeffs, tr_energies]\n",
    "    test_data: [te_adjs, te_coeffs, te_energies]\n",
    "\"\"\"\n",
    "train_data,test_data = split_data(SIMS_adj_uniq,SIMS_scar_uniq,SIMS_G_uniq)  # multiple trj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('vida')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "e442af4fad2330d8f4febe7e8e7250535e161341429a4f0b93cbf21b824330cc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
