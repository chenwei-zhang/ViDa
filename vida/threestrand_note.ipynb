{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import pickle\n",
    "import gzip\n",
    "\n",
    "import sys\n",
    "sys.path.append('/Users/chenwei/Desktop/Github/ViDa') \n",
    "\n",
    "import imp, vida.data_processing.utils\n",
    "imp.reload(vida.data_processing.utils)\n",
    "from vida.data_processing.utils import *\n",
    "\n",
    "import imp, vida.adjmat.dp2adj\n",
    "imp.reload(vida.adjmat.dp2adj)\n",
    "from vida.adjmat.dp2adj import *\n",
    "\n",
    "import imp, vida.data_processing.comp_time\n",
    "imp.reload(vida.data_processing.comp_time)\n",
    "from vida.data_processing.comp_time import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### three way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = '/Users/chenwei/Desktop/Github/ViDa//data/raw_data/Machinek-data'\n",
    "rxn = 'Machinek-PRF'\n",
    "ref_strands = 'CCCTCCACATTCAACCTCAAACTCACC+TGGTGTTTGTGGGTGTGGTGAGTTTGAGGTTGA+GGTGAGTTTGAGGTTGAATGTGGA'\n",
    "strand_a = 'CCCTCCACATTCAACCTCAAACTCACC'  # substrate_perf_seq\n",
    "strand_b = 'TGGTGTTTGTGGGTGTGGTGAGTTTGAGGTTGA'  # incumbent_perf_seq\n",
    "strand_c = 'GGTGAGTTTGAGGTTGAATGTGGA'  # invader_perf_seq\n",
    "strand_list = [strand_a, strand_b, strand_c]\n",
    "\n",
    "ref_name_list = assign_base_names(ref_strands)\n",
    "ref_name = [item for sublist in ref_name_list for item in sublist]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strand_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f = open('/Users/chenwei/Desktop/Github/ViDa/data/raw_data/Machinek-data/Machinek-PRF/Machinek-PRF-0.txt', 'r')\n",
    "# lines = f.read().splitlines()\n",
    "# part_strand = 'GGTGAGTTTGAGGTTGAATGTGGA'\n",
    "# seq_line = []\n",
    "# pattern = re.compile(r'^(.*?)\\s+t=([\\d.e+-]+) seconds, dG=([-\\d.e+]+) kcal/mol')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajs_seqs, trajs_states, trajs_times, trajs_energies = read_machinek(fpath,rxn,strand_a,num_files=1)\n",
    "trajs_seqs.shape, trajs_states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajs_seqs[0][-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp_arr, dp_og, pair, energy, trans_time = concat_machinek(trajs_states, trajs_times, trajs_energies)\n",
    "dp_uniq, dp_og_uniq, pair_uniq, energy_uniq, indices_uniq, indices_all = get_uniq(dp_arr, dp_og, pair, energy)\n",
    "adj_uniq, seqlabel_uniq = sim_adj_3strand_uniq(dp_arr, trajs_seqs, ref_name, ref_name_list, strand_list, indices_uniq)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### adj_uqni debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp_arr.shape, dp_arr[0].shape, trajs_seqs.shape, len(trajs_seqs[0]), adj_uniq.shape, seqlabel_uniq.shape, indices_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "la = 980\n",
    "lb = la+10\n",
    "\n",
    "seqlabel_uniq[la:lb], dp_og_uniq[la:lb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp_og_uniq[-1], adj_uniq[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp_og_uniq[-1], dp_uniq[-1], seqlabel_uniq[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "## TEST 1\n",
    "## Calculate the adjacency matrix for the individual structure ##\n",
    "\n",
    "\"\"\"\n",
    "dp_structure = dp_uniq[-1]\n",
    "\n",
    "alter_name_arr = concat_disorder(trajs_seqs[0],ref_name_list, strand_list)\n",
    "\n",
    "alter_name_arr_test = alter_name_arr[-1]\n",
    "\n",
    "alter_name = np.concatenate(alter_name_arr_test)\n",
    "\n",
    "dplast = dp2adj_3strand(ref_name, alter_name, alter_name_arr_test, dp_structure)\n",
    "dplast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "## TEST 2\n",
    "## Calculate the whole adjacency matrix than compared with uniq ones ##\n",
    "\n",
    "\"\"\"\n",
    "dppmat = sim_adj_3strand(dp_arr, trajs_sequences, ref_name, ref_name_list, strand_list)\n",
    "dppmat_uniq = dppmat[indices_uniq]\n",
    "\n",
    "np.all(adj_uniq == dppmat_uniq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UNCHANGE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### collect time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hold_time, trj_id = sim_ht(trans_time)\n",
    "hold_time_uniq = mean_holdingtime(hold_time, indices_uniq, indices_all)\n",
    "cum_time_uniq,freq_uniq = cumu_holdingtime(hold_time, indices_uniq, indices_all)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dp to adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_uniq = sim_adj_3strand_uniq(dp_arr, trajs_seqs, ref_name, ref_name_list, strand_list, indices_uniq)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_array = np.concatenate(adj, axis=0)\n",
    "combined_array.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Draw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a graph from the adjacency matrix\n",
    "G = nx.Graph(adj[10])\n",
    "\n",
    "# Draw the graph\n",
    "pos = nx.spring_layout(G)  # Positions for all nodes\n",
    "nx.draw(G, pos=nx.kamada_kawai_layout(G), with_labels=True, font_weight='bold', node_size=200, node_color='green', font_size=10, font_color='black')\n",
    "# nx.draw(G, with_labels=True, font_weight='bold', node_size=200, node_color='green', font_size=10, font_color='black')\n",
    "\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import pickle\n",
    "import gzip\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append('/Users/chenwei/Desktop/Github/ViDa') \n",
    "\n",
    "\n",
    "import imp, vida.data_processing.strandReorder\n",
    "imp.reload(vida.data_processing.strandReorder)\n",
    "from vida.data_processing.strandReorder import *\n",
    "\n",
    "# import imp, vida.data_processing.utils\n",
    "# imp.reload(vida.data_processing.utils)\n",
    "# from vida.data_processing.utils import *\n",
    "\n",
    "import imp, vida.adjmat.dp2adj\n",
    "imp.reload(vida.adjmat.dp2adj)\n",
    "from vida.adjmat.dp2adj import *\n",
    "\n",
    "import imp, vida.data_processing.comp_time\n",
    "imp.reload(vida.data_processing.comp_time)\n",
    "from vida.data_processing.comp_time import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafile='Machinek-PRF-trunc'\n",
    "\n",
    "ref_strands = 'CCCTCCACATTCAACCTCAAACTCACC+TGGTGTTTGTGGGTGTGGTGAGTTTGAGGTTGA+GGTGAGTTTGAGGTTGAATGTGGA'\n",
    "strand_sub = 'CCCTCCACATTCAACCTCAAACTCACC'  # substrate_perf_seq\n",
    "strand_incb = 'TGGTGTTTGTGGGTGTGGTGAGTTTGAGGTTGA'  # incumbent_perf_seq\n",
    "strand_inv = 'GGTGAGTTTGAGGTTGAATGTGGA'  # invader_perf_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "inpath = f'../data/post_data/{datafile}/preprocess_Machinek-PRF.npz'\n",
    "loaded_data = np.load(inpath, allow_pickle=True)\n",
    "dp_uniq = loaded_data['dp_uniq']\n",
    "dp_og_uniq = loaded_data['dp_og_uniq']\n",
    "shortname_uniq = loaded_data['shortname_uniq']\n",
    "incbinvpair_uniq = loaded_data['incbinvpair_uniq']\n",
    "indices_uniq = loaded_data['indices_uniq']\n",
    "indices_all = loaded_data['indices_all']\n",
    "trans_time = loaded_data[\"trans_time\"]\n",
    "energy_uniq = loaded_data[\"energy_uniq\"]\n",
    "ref_name = loaded_data[\"ref_name\"]\n",
    "ref_name_list = loaded_data[\"ref_name_list\"]\n",
    "strand_list = loaded_data[\"strand_list\"]\n",
    "\n",
    "inpath2 = f'../data/post_data/{datafile}/Machinek-PRF.pkl.gz'\n",
    "with gzip.open(inpath2, 'rb') as file:\n",
    "    load_data_seq = pickle.load(file)\n",
    "\n",
    "ref_name = load_data_seq[\"ref_name\"]\n",
    "ref_name_list = load_data_seq[\"ref_name_list\"]\n",
    "strand_list = load_data_seq[\"strand_list\"]\n",
    "trajs_seqs = load_data_seq[\"trajs_seqs\"]\n",
    "trajs_states = load_data_seq['trajs_states']\n",
    "trajs_times = load_data_seq['trajs_times']\n",
    "trajs_energies = load_data_seq['trajs_energies']\n",
    "trajs_shortnames = load_data_seq['trajs_shortnames']\n",
    "trajs_incbinvpairs = load_data_seq['trajs_incbinvpairs']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data={\n",
    "                \"Energy\": energy_uniq, \"DP\": dp_og_uniq, \n",
    "                \"IncbInvPair\": incbinvpair_uniq, \"ShortName\": shortname_uniq,\n",
    "                }\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_mapping = {\n",
    "        \"inv+sub+incb\": \"grey\",\n",
    "        \"incb+sub+inv\": \"red\",\n",
    "        \"incb+sub inv\": \"blue\",    \n",
    "        \"incb sub+inv\": \"orange\",\n",
    "    }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'grey'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "color_mapping[df['ShortName'][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['incb sub+inv' 'incb+sub inv' 'incb+sub+inv' 'inv+sub+incb']\n",
      "[   32   611   178 15522]\n"
     ]
    }
   ],
   "source": [
    "unique_values, counts = np.unique(shortname_uniq, return_counts=True)\n",
    "print(unique_values)  # Output: array of unique values\n",
    "print(counts)  # Output: corresponding counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 400, 400, 400, 400, 400)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trajs_seqs), len(trajs_shortnames), len(trajs_incbinvpairs), len(trajs_states), len(trajs_times), len(trajs_energies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16343,), (16343,), (16343,), (16343,), (16343,), (4363808,), (4363808,))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dp_uniq.shape, dp_og_uniq.shape, shortname_uniq.shape, incbinvpair_uniq.shape, indices_uniq.shape, indices_all.shape, trans_time.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4363808,),\n",
       " (4363808,),\n",
       " (4363808,),\n",
       " (4363808,),\n",
       " (4363808,),\n",
       " (4363808,),\n",
       " (4363808,),\n",
       " (4363808,))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dp, dp_og, pair, energy, trans_time, seq, shortname, incbinvpair= concat_machinek(trajs_states, trajs_times, trajs_energies, trajs_seqs, trajs_shortnames, trajs_incbinvpairs)\n",
    "\n",
    "dp.shape, pair.shape, dp_og.shape, energy.shape, trans_time.shape, seq.shape, shortname.shape, incbinvpair.shape,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dp2adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16343, 84, 84)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inpath3 = f'../data/post_data/{datafile}/adjmat_Machinek-PRF.npz'\n",
    "loaded_data3 = np.load(inpath3, allow_pickle=True)\n",
    "adj_uniq = loaded_data3['adj_uniq']\n",
    "\n",
    "adj_uniq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16343, 7056)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(adj_uniq.reshape(adj_uniq.shape[0], -1), axis=0).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from itertools import permutations\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class ThreeStrandReorder:\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_strand_pos(bpair):\n",
    "        pattern = r'([a-z])(\\d+)([a-z])(\\d+)'\n",
    "        match = re.match(pattern, bpair)\n",
    "\n",
    "        if match:\n",
    "            strand1, pos1, strand2, pos2 = match.groups()\n",
    "            pos1 = int(pos1) - 1  # Convert to 0-based index\n",
    "            pos2 = int(pos2) - 1  # Convert to 0-based index\n",
    "            return strand1, pos1, strand2, pos2\n",
    "        else:\n",
    "            raise ValueError(\"Invalid base pair format\")\n",
    "\n",
    "    @staticmethod\n",
    "    def hasIncbInvPair(base_pairs):\n",
    "        has_bc = any('b' in pair and 'c' in pair for pair in base_pairs)\n",
    "\n",
    "        return 1 if has_bc else 0\n",
    "    \n",
    "    \n",
    "    def get_basepairs(self, seq, dp, ref_name_list, strand_list):\n",
    "        def concat_disorder(seq, ref_name_list, strand_list):\n",
    "            sequence_list = re.split(r'\\s|\\+', seq) \n",
    "            sequence = ''.join(sequence_list)\n",
    "\n",
    "            for permuted_strand in permutations(strand_list):\n",
    "                combined_sequence = ''.join(permuted_strand)\n",
    "                if combined_sequence == sequence:\n",
    "                    alter_name = [ref_name_list[strand_list.index(strand)] for strand in permuted_strand]\n",
    "                    break\n",
    "\n",
    "            return np.concatenate(alter_name)\n",
    "\n",
    "        dp_structure = dp.replace(' ', '').replace('+', '')\n",
    "        alter_name = concat_disorder(seq, ref_name_list, strand_list)\n",
    "\n",
    "        stack = []\n",
    "        base_pairs = []\n",
    "\n",
    "        for name, char in zip(alter_name, dp_structure):\n",
    "            if char == '(':\n",
    "                stack.append(name)\n",
    "            elif char == ')':\n",
    "                if stack:\n",
    "                    opening_index = stack.pop()\n",
    "                    base_pairs.append(opening_index + name)\n",
    "                else:\n",
    "                    raise ValueError(\"Mismatched brackets\")\n",
    "\n",
    "        if stack:\n",
    "            raise ValueError(\"Mismatched brackets\")\n",
    "\n",
    "        return base_pairs\n",
    "\n",
    "    def reorderCase1(self, case1, dp, seq, short_seqname, ref_name_list, strand_list):\n",
    "        \"\"\"\n",
    "        Reorder:\n",
    "        'incb+inv+sub' -> 'inv+sub+incb' \n",
    "        'sub+incb+inv' -> 'inv+sub+incb'\n",
    "        \"\"\"\n",
    "        \n",
    "        position = case1.index(short_seqname)\n",
    "        base_pairs = self.get_basepairs(seq, dp, ref_name_list, strand_list)\n",
    "        \n",
    "        incb_inv_pair = ThreeStrandReorder.hasIncbInvPair(base_pairs)\n",
    "                \n",
    "        if position == 0:   # 'inv+sub+incb': c+a+b ===> do nothing\n",
    "            return dp, short_seqname, incb_inv_pair\n",
    "        \n",
    "        \n",
    "        if position == 1:  # 'incb+inv+sub': b+c+a ===> c+a+b\n",
    "            incb_list, inv_list, sub_list = [list(part) for part in re.split(r'\\s|\\+', dp)]\n",
    "            \n",
    "            for bpair in base_pairs:\n",
    "                strand1, pos1, strand2, pos2 = ThreeStrandReorder.get_strand_pos(bpair)\n",
    "                \n",
    "                # only need to change incb (b) with its connected strands\n",
    "                if strand1 == 'b' and strand2 == 'c':\n",
    "                    incb_list[pos1] = ')'\n",
    "                    inv_list[pos2] = '('\n",
    "\n",
    "                if strand1 == 'b' and strand2 == 'a':\n",
    "                    incb_list[pos1] = ')'\n",
    "                    sub_list[pos2] = '('\n",
    "\n",
    "\n",
    "        if position == 2: # 'sub+incb+inv': a+b+c ===> c+a+b\n",
    "            sub_list, incb_list, inv_list = [list(part) for part in re.split(r'\\s|\\+', dp)]\n",
    "            \n",
    "            for bpair in base_pairs:\n",
    "                strand1, pos1, strand2, pos2 = ThreeStrandReorder.get_strand_pos(bpair)\n",
    "            \n",
    "                # only need to change inv (c) with its connected strands\n",
    "                if strand1 == 'a' and strand2 == 'c':\n",
    "                    inv_list[pos2] = '('\n",
    "                    sub_list[pos1] = ')'\n",
    "                                    \n",
    "                if strand1 == 'b' and strand2 == 'c':\n",
    "                    inv_list[pos2] = '('\n",
    "                    incb_list[pos1] = ')'\n",
    "        \n",
    "        inv = ''.join(inv_list)\n",
    "        sub = ''.join(sub_list)\n",
    "        incb = ''.join(incb_list)\n",
    "        # inv+sub+incb\n",
    "        dp_new = inv + \"+\" + sub + \"+\" + incb\n",
    "        \n",
    "        return dp_new, case1[0], incb_inv_pair\n",
    "\n",
    "\n",
    "    def reorderCase2(self, case2, dp, seq, short_seqname, ref_name_list, strand_list):\n",
    "        \"\"\"\n",
    "        Reorder:\n",
    "        'inv+incb+sub' -> 'incb+sub+inv' \n",
    "        'sub+inv+incb' -> 'incb+sub+inv'\n",
    "        \"\"\"\n",
    "        \n",
    "        position = case2.index(short_seqname)\n",
    "        base_pairs = self.get_basepairs(seq, dp, ref_name_list, strand_list)\n",
    "        \n",
    "        incb_inv_pair = ThreeStrandReorder.hasIncbInvPair(base_pairs)\n",
    "                \n",
    "        if position == 0:   # 'incb+sub+inv': b+a+c ===> do nothing\n",
    "            return dp, short_seqname, incb_inv_pair\n",
    "        \n",
    "        if position == 1:  # 'inv+incb+sub': c+b+a ===> b+a+c\n",
    "            inv_list, incb_list, sub_list = [list(part) for part in re.split(r'\\s|\\+', dp)]\n",
    "            \n",
    "            for bpair in base_pairs:\n",
    "                strand1, pos1, strand2, pos2 = ThreeStrandReorder.get_strand_pos(bpair)\n",
    "                \n",
    "                # only need to change inv (c) with its connected strands\n",
    "                if strand1 == 'c' and strand2 == 'b':\n",
    "                    inv_list[pos1] = ')'\n",
    "                    incb_list[pos2] = '('\n",
    "                    incb_inv_pair = 1\n",
    "                    \n",
    "                if strand1 == 'c' and strand2 == 'a':\n",
    "                    inv_list[pos1] = ')'\n",
    "                    sub_list[pos2] = '('\n",
    "        \n",
    "        \n",
    "        if position == 2: # 'sub+inv+incb': a+c+b ===> b+a+c\n",
    "            sub_list, incb_list, inv_list = [list(part) for part in re.split(r'\\s|\\+', dp)]\n",
    "            \n",
    "            for bpair in base_pairs:\n",
    "                strand1, pos1, strand2, pos2 = ThreeStrandReorder.get_strand_pos(bpair)\n",
    "            \n",
    "                # only need to change incb (b) with its connected strands\n",
    "                if strand1 == 'a' and strand2 == 'b':\n",
    "                    incb_list[pos2] = '('\n",
    "                    sub_list[pos1] = ')'\n",
    "                    \n",
    "                if strand1 == 'c' and strand2 == 'b':\n",
    "                    incb_list[pos2] = '('\n",
    "                    inv_list[pos1] = ')'\n",
    "        \n",
    "        inv = ''.join(inv_list)\n",
    "        sub = ''.join(sub_list)\n",
    "        incb = ''.join(incb_list)\n",
    "        # incb+sub+inv\n",
    "        dp_new = incb + \"+\" + sub + \"+\" + inv\n",
    "        \n",
    "        return dp_new, case2[0], incb_inv_pair\n",
    "\n",
    "\n",
    "    def reorderCase3(self, case3, dp, seq, short_seqname, ref_name_list, strand_list):\n",
    "        \"\"\"\n",
    "        Reorder:\n",
    "        'sub+incb inv' -> 'incb+sub inv' \n",
    "        'inv sub+incb' -> 'incb+sub inv'\n",
    "        'sub+inv incb' -> 'incb+sub inv' \n",
    "        \"\"\"\n",
    "        \n",
    "        position = case3.index(short_seqname)\n",
    "        \n",
    "        incb_inv_pair = 0 # certainly no incumbent-invader pair\n",
    "                \n",
    "        if position == 0:   # 'incb+sub inv': b+a c ===> do nothing\n",
    "            return dp, short_seqname, incb_inv_pair\n",
    "        \n",
    "        \n",
    "        base_pairs = self.get_basepairs(seq, dp, ref_name_list, strand_list)\n",
    "        \n",
    "        if position == 1:  # 'sub+incb inv': a+b c ===> b+a c\n",
    "            sub_list, incb_list, inv_list  = [list(part) for part in re.split(r'\\s|\\+', dp)]\n",
    "            \n",
    "            for bpair in base_pairs:\n",
    "                strand1, pos1, strand2, pos2 = ThreeStrandReorder.get_strand_pos(bpair)\n",
    "                \n",
    "                # only need to change incb (b) with its connected strand sub (a)\n",
    "                if strand1 == 'a' and strand2 == 'b':\n",
    "                    incb_list[pos2] = '('\n",
    "                    sub_list[pos1] = ')'\n",
    "        \n",
    "        \n",
    "        if position == 2: # 'inv sub+incb': c a+b ===> b+a c\n",
    "            inv_list, sub_list, incb_list = [list(part) for part in re.split(r'\\s|\\+', dp)]\n",
    "            \n",
    "            for bpair in base_pairs:\n",
    "                strand1, pos1, strand2, pos2 = ThreeStrandReorder.get_strand_pos(bpair)\n",
    "                \n",
    "                # only need to change incb (b) with its connected strand sub (a)\n",
    "                if strand1 == 'a' and strand2 == 'b':\n",
    "                    incb_list[pos2] = '('\n",
    "                    sub_list[pos1] = ')'\n",
    "                    \n",
    "        \n",
    "        if position == 3: # 'inv incb+sub': c b+a ===> b+a c\n",
    "            inv_list, incb_list, sub_list = [list(part) for part in re.split(r'\\s|\\+', dp)]\n",
    "            # just need to exchange the position of inv and incb+sub\n",
    "            \n",
    "        inv = ''.join(inv_list)\n",
    "        sub = ''.join(sub_list)\n",
    "        incb = ''.join(incb_list)\n",
    "        # incb+sub inv\n",
    "        dp_new = incb + \"+\" + sub + \" \" + inv\n",
    "        \n",
    "        return dp_new, case3[0], incb_inv_pair\n",
    "\n",
    "\n",
    "    def reorderCase4(self, case4, dp, seq, short_seqname, ref_name_list, strand_list):\n",
    "        \"\"\"\n",
    "        Reorder:\n",
    "        'incb inv+sub' -> 'incb sub+inv' \n",
    "        'inv+sub incb' -> 'incb sub+inv' \n",
    "        'sub+inv incb' -> 'incb sub+inv' \n",
    "        \"\"\"\n",
    "        \n",
    "        position = case4.index(short_seqname)\n",
    "        \n",
    "        incb_inv_pair = 0 # certainly no incumbent-invader pair\n",
    "                \n",
    "        if position == 0:   # 'incb sub+inv': b a+c ===> do nothing\n",
    "            return dp, short_seqname, incb_inv_pair\n",
    "        \n",
    "        \n",
    "        base_pairs = self.get_basepairs(seq, dp, ref_name_list, strand_list)\n",
    "        \n",
    "        if position == 1:  # 'incb inv+sub': b c+a ===> b a+c\n",
    "            incb_list, inv_list, sub_list = [list(part) for part in re.split(r'\\s|\\+', dp)]\n",
    "            \n",
    "            for bpair in base_pairs:\n",
    "                strand1, pos1, strand2, pos2 = ThreeStrandReorder.get_strand_pos(bpair)\n",
    "                \n",
    "                # only need to change inv (c) with its connected strand sub (a)\n",
    "                if strand1 == 'c' and strand2 == 'a':\n",
    "                    inv_list[pos1] = ')'\n",
    "                    sub_list[pos2] = '('\n",
    "                    \n",
    "        \n",
    "        if position == 2: # 'inv+sub incb': c+a b ===> b a+c\n",
    "            inv_list, sub_list, incb_list = [list(part) for part in re.split(r'\\s|\\+', dp)]\n",
    "            \n",
    "            for bpair in base_pairs:\n",
    "                strand1, pos1, strand2, pos2 = ThreeStrandReorder.get_strand_pos(bpair)\n",
    "                \n",
    "                # only need to change inv (c) with its connected strand sub (a)\n",
    "                if strand1 == 'c' and strand2 == 'a':\n",
    "                    inv_list[pos1] = ')'\n",
    "                    sub_list[pos2] = '('\n",
    "        \n",
    "        \n",
    "        if position == 3: # 'sub+inv incb': a+c b ===> b a+c\n",
    "            sub_list, inv_list, incb_list = [list(part) for part in re.split(r'\\s|\\+', dp)]\n",
    "            # just need to exchange the position of sub+inv and incb\n",
    "            \n",
    "        inv = ''.join(inv_list)\n",
    "        sub = ''.join(sub_list)\n",
    "        incb = ''.join(incb_list)\n",
    "        # incb sub+inv\n",
    "        dp_new = incb + \" \" + sub + \"+\" + inv\n",
    "        \n",
    "        return dp_new, case4[0], incb_inv_pair\n",
    "\n",
    "\n",
    "    def reorderCase5(self, case5, dp, seq, short_seqname, ref_name_list, strand_list):\n",
    "        \"\"\"\n",
    "        Reorder:\n",
    "        'inv+incb sub' -> 'incb+inv sub' \n",
    "        'sub inv+incb' -> 'incb+inv sub' \n",
    "        'sub incb+inv' -> 'incb+inv sub' \n",
    "        \"\"\"\n",
    "        \n",
    "        position = case5.index(short_seqname)\n",
    "        \n",
    "        incb_inv_pair = 1 # certainly having incumbent-invader pair\n",
    "                \n",
    "        if position == 0:   # 'incb+inv sub': b+c a ===> do nothing\n",
    "            return dp, short_seqname, incb_inv_pair\n",
    "        \n",
    "        \n",
    "        base_pairs = self.get_basepairs(seq, dp, ref_name_list, strand_list)\n",
    "        \n",
    "        if position == 1:  # 'inv+incb sub': c+b a ===> b+c a\n",
    "            inv_list, incb_list, ub_list = [list(part) for part in re.split(r'\\s|\\+', dp)]\n",
    "            \n",
    "            for bpair in base_pairs:\n",
    "                strand1, pos1, strand2, pos2 = ThreeStrandReorder.get_strand_pos(bpair)\n",
    "                \n",
    "                # only need to change inv (c) with its connected strand incb (b)\n",
    "                if strand1 == 'c' and strand2 == 'b':\n",
    "                    inv_list[pos1] = ')'\n",
    "                    incb_list[pos2] = '('\n",
    "                    \n",
    "        \n",
    "        if position == 2: # 'sub inv+incb': a c+b ===> b+c a\n",
    "            sub_list, inv_list, incb_list = [list(part) for part in re.split(r'\\s|\\+', dp)]\n",
    "            \n",
    "            for bpair in base_pairs:\n",
    "                strand1, pos1, strand2, pos2 = ThreeStrandReorder.get_strand_pos(bpair)\n",
    "                \n",
    "                # only need to change inv (c) with its connected strand incb (b)\n",
    "                if strand1 == 'c' and strand2 == 'b':\n",
    "                    inv_list[pos1] = ')'\n",
    "                    incb_list[pos2] = '('\n",
    "        \n",
    "        \n",
    "        if position == 3: # 'sub incb+inv': a b+c ===> b+c a\n",
    "            sub_list, incb_list, inv_list = [list(part) for part in re.split(r'\\s|\\+', dp)]\n",
    "            # just need to exchange the position of sub and incb+inv\n",
    "            \n",
    "        inv = ''.join(inv_list)\n",
    "        sub = ''.join(sub_list)\n",
    "        incb = ''.join(incb_list)\n",
    "        # incb+inv sub\n",
    "        dp_new = incb + \"+\" + inv + \" \" + sub\n",
    "        \n",
    "        return dp_new, case5[0], incb_inv_pair\n",
    "\n",
    "\n",
    "    def reorderCase6(self, case6, dp, seq, short_seqname, ref_name_list, strand_list):\n",
    "        \"\"\"\n",
    "        Reorder:\n",
    "        'incb inv sub' -> 'incb sub inv' \n",
    "        'sub inv incb' -> 'incb sub inv' \n",
    "        'sub incb inv' -> 'incb sub inv' \n",
    "        'inv incb sub' -> 'incb sub inv' \n",
    "        'inv sub incb' -> 'incb sub inv' \n",
    "        \"\"\"\n",
    "        \n",
    "        position = case6.index(short_seqname)\n",
    "        \n",
    "        incb_inv_pair = 0 # certainly not incumbent-invader pair\n",
    "                \n",
    "        if position == 0:   # 'incb sub inv': b a c ===> do nothing\n",
    "            return dp, short_seqname, incb_inv_pair\n",
    "            \n",
    "        if position == 1:  # 'incb inv sub': b c a ===> b a c\n",
    "            incb_list, inv_list, sub_list = [list(part) for part in re.split(r'\\s|\\+', dp)]\n",
    "        \n",
    "        if position == 2: # 'sub inv incb': a c b ===> b a c\n",
    "            sub_list, inv_list, incb_list = [list(part) for part in re.split(r'\\s|\\+', dp)]\n",
    "        \n",
    "        if position == 3: # 'sub incb inv': a b c ===> b a c\n",
    "            sub_list, incb_list, inv_list = [list(part) for part in re.split(r'\\s|\\+', dp)]\n",
    "\n",
    "        if position == 4: # 'inv incb sub': c b a ===> b a c\n",
    "            inv_list, incb_list, sub_list = [list(part) for part in re.split(r'\\s|\\+', dp)]\n",
    "        \n",
    "        if position == 5: # 'inv sub incb': c a b ===> b a c\n",
    "            inv_list, sub_list, incb_list = [list(part) for part in re.split(r'\\s|\\+', dp)]\n",
    "                \n",
    "        inv = ''.join(inv_list)\n",
    "        sub = ''.join(sub_list)\n",
    "        incb = ''.join(incb_list)\n",
    "        # incb sub inv\n",
    "        dp_new = incb + \" \" + sub + \" \" + inv\n",
    "        \n",
    "        return dp_new, case6[0], incb_inv_pair\n",
    "    \n",
    "    def nameMap(self, sequence, strand_sub, strand_incb, strand_inv):\n",
    "        def replace_strings(s):\n",
    "            s = s.replace(strand_inv, \"inv\")\n",
    "            s = s.replace(strand_incb, \"incb\")\n",
    "            s = s.replace(strand_sub, \"sub\")\n",
    "            return s\n",
    "\n",
    "        vectorized_replace = np.vectorize(replace_strings)\n",
    "\n",
    "        return vectorized_replace(np.array([sequence])).tolist()[0]\n",
    "    \n",
    "    def dp_reorder(self, dp, seq, ref_name_list, strand_list, strand_sub, strand_incb, strand_inv):\n",
    "    \n",
    "        short_seqname = self.nameMap(seq, strand_sub, strand_incb, strand_inv)\n",
    "        \n",
    "        case1 = ['inv+sub+incb', 'incb+inv+sub', 'sub+incb+inv']\n",
    "        case2 = ['incb+sub+inv', 'inv+incb+sub', 'sub+inv+incb']\n",
    "        case3 = ['incb+sub inv', 'sub+incb inv', 'inv sub+incb', 'inv incb+sub'] \n",
    "        case4 = ['incb sub+inv', 'incb inv+sub', 'inv+sub incb', 'sub+inv incb'] \n",
    "        case5 = ['incb+inv sub', 'inv+incb sub', 'sub inv+incb', 'sub incb+inv'] ##\n",
    "        case6 = ['incb sub inv', 'incb inv sub', 'sub inv incb' 'sub incb inv' 'inv incb sub' 'inv sub incb']\n",
    "        \n",
    "        if short_seqname in case1:\n",
    "            dp_new, short_seqname, incb_inv_pair = self.reorderCase1(case1, dp, seq, short_seqname, ref_name_list, strand_list)\n",
    "            \n",
    "        if short_seqname in case2:\n",
    "            dp_new, short_seqname, incb_inv_pair = self.reorderCase2(case2, dp, seq, short_seqname, ref_name_list, strand_list)\n",
    "        \n",
    "        if short_seqname in case3:\n",
    "            dp_new, short_seqname, incb_inv_pair = self.reorderCase3(case3, dp, seq, short_seqname, ref_name_list, strand_list)\n",
    "            \n",
    "        if short_seqname in case4:\n",
    "            dp_new, short_seqname, incb_inv_pair = self.reorderCase4(case4, dp, seq, short_seqname, ref_name_list, strand_list)\n",
    "        \n",
    "        if short_seqname in case5:\n",
    "            dp_new, short_seqname, incb_inv_pair = self.reorderCase5(case5, dp, seq, short_seqname, ref_name_list, strand_list)\n",
    "        \n",
    "        if short_seqname in case6:\n",
    "            dp_new, short_seqname, incb_inv_pair = self.reorderCase6(case6, dp, seq, short_seqname, ref_name_list, strand_list)\n",
    "        \n",
    "        return dp_new, short_seqname, incb_inv_pair\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sub+incb+inv ((....((..(((((((((((((((((+................)))))))))))))))))+......((((....)))).)))).\n",
      "\n",
      "......((((....)))).((((.+))....))..(((((((((((((((((+................))))))))))))))))) inv+sub+incb 0\n"
     ]
    }
   ],
   "source": [
    "reoder_3strand = ThreeStrandReorder()\n",
    "\n",
    "num = 1560\n",
    "\n",
    "seq = seqlabel_uniq[num]\n",
    "dp = dp_og_uniq[num]\n",
    "print(arr_short[num], dp)\n",
    "print()\n",
    "\n",
    "p_new, short_seqname, incb_inv_pair = reoder_3strand.dp_reorder(dp, seq, ref_name_list, strand_list, strand_sub, strand_incb, strand_inv)\n",
    "print(p_new, short_seqname, incb_inv_pair)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case1 = ['inv+sub+incb', 'sub+incb+inv', 'incb+inv+sub',]\n",
    "case2 = ['incb+sub+inv', 'inv+incb+sub', 'sub+inv+incb']\n",
    "case3 = ['incb+sub inv', 'sub+incb inv', 'inv sub+incb', 'inv incb+sub'] \n",
    "case4 = ['incb sub+inv', 'incb inv+sub', 'inv+sub incb', 'sub+inv incb'] \n",
    "case5 = ['incb+inv sub', 'inv+incb sub', 'sub inv+incb', 'sub incb+inv'] ##\n",
    "\n",
    "np.where(arr_short == case1[0])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load embeddings\n",
    "\n",
    "TNAME = '24-0214-2008'\n",
    "CKPT = 'checkpoint_epoch_39'\n",
    "# CKPT = 'model'\n",
    "\n",
    "inpath5 = f'../data/post_data/{datafile}/model_config/{TNAME}/embed_{CKPT}_Machinek-PRF.npz'\n",
    "loaded_data5 = np.load(inpath5, allow_pickle=True)\n",
    "embeddings = loaded_data5['embeddings']\n",
    "embeddings.max(), embeddings.min(), embeddings.mean(), embeddings.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = PCA(n_components=25)\n",
    "cm.fit(embeddings)\n",
    "\n",
    "PC_values = np.arange(cm.n_components_) + 1\n",
    "plt.plot(PC_values, np.cumsum(cm.explained_variance_ratio_), 'ro-', linewidth=2)\n",
    "plt.title('Scree Plot: PCA')\n",
    "plt.xlabel('Number of principal components')\n",
    "plt.ylabel('Cumulative explained variance');\n",
    "# plt.xticks(np.arange(0, data_embed.shape[-1]+1, 1))\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(np.cumsum(cm.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "\n",
    "\n",
    "datafile = 'Machinek-PRF-trunc'\n",
    "\n",
    "inpath = f'../data/post_data/{datafile}/preprocess_Machinek-PRF.npz'\n",
    "loaded_data = np.load(inpath, allow_pickle=True)\n",
    "trans_time = loaded_data[\"trans_time\"]\n",
    "\n",
    "inpath4 = f'../data/post_data/{datafile}/time_Machinek-PRF.npz'\n",
    "loaded_data4 = np.load(inpath4, allow_pickle=True)\n",
    "trj_id = loaded_data4['trj_id']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rxnTimes = trans_time[trj_id]\n",
    "ids = np.arange(rxnTimes.shape[0])\n",
    "\n",
    "sortTimes = np.sort(rxnTimes)[::-1]\n",
    "sortIDs = ids[np.argsort(rxnTimes)[::-1]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(x=ids, y=sortTimes, hover_data=[sortIDs], log_y=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(sortTimes), np.max(sortTimes), np.min(sortTimes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vida",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
